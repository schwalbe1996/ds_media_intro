{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colabで開く](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/schwalbe1996/ds_media_intro/blob/main/chap12.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12章 「画像の基本的な処理」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "image = cv2.imread('foreground.png') # 前景画像の読み込み\n",
    "\n",
    "HSV_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) # HSV空間への変換\n",
    "H = HSV_image[:,:,0] # 色相(H)の抽出\n",
    "S = HSV_image[:,:,1] # 彩度(S)の抽出\n",
    "V = HSV_image[:,:,2] # 明度(V)の抽出\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(H, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(S, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(V, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = cv2.imread('sample.png') # 背景画像の読み込み\n",
    "    \n",
    "H_mask = cv2.inRange(H, 100, 140) # 青色の範囲(100～140)を抽出\n",
    "S_mask = cv2.inRange(S, 100, 255) # 彩度の範囲(100～255)を抽出\n",
    "mask = H_mask * S_mask # 青色の範囲と彩度の範囲の共通部分を抽出\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# 前景画像の青色部分を背景画像に合成\n",
    "output = image.copy()\n",
    "output[mask!=0] = background[mask!=0]\n",
    "\n",
    "plt.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "cv2.imwrite('output.png', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('sudoku.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 単純閾値処理\n",
    "t = 50\n",
    "# opencvの関数を使う場合\n",
    "ret, result = cv2.threshold(image, t, 255, cv2.THRESH_BINARY)\n",
    "# opencvを使わない場合\n",
    "result = (image > t) * 255\n",
    "\n",
    "plt.imshow(result,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像(image)は2次元配列なので，flatten()を用いて1次元配列に整形してからヒストグラムを作成する\n",
    "_ = plt.hist(image.flatten(), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値を0，cv2.THRESH_BINARY の代わりにcv2.THRESH_BINARY+cv2.THRESH_OTSU を指定する\n",
    "ret, result = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print (ret) # 大津の方法で決定された閾値\n",
    "\n",
    "plt.imshow(result, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B=25, C=10の場合\n",
    "result = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 25, 10)\n",
    "\n",
    "plt.imshow(result, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('sample.png')\n",
    "height,width,_ = image.shape\n",
    "\n",
    "# 回転の例\n",
    "# 画像の中心を中心に30°回転、拡大率1.0の例\n",
    "mat = cv2.getRotationMatrix2D((width//2,height//2), 30, 1.0)\n",
    "dst = cv2.warpAffine(image, mat, (width,height))\n",
    "print(mat)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(dst,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "# 平面射影変換の例\n",
    "\"\"\"\n",
    "- (0,0) --> (50, 50)\n",
    "- 画像の左下 --> そのまま\n",
    "- 画像の右上 --> 画像の右上から80ピクセル左\n",
    "- 画像の右下 --> 画像の右下から30ピクセル上\n",
    "\"\"\"\n",
    "srcP = np.array([[0,0],[0,height],[width,0],[width,height]], dtype=np.float32)\n",
    "dstP = np.array([[50,50],[0,height],[width-80,0],[width,height-30]], dtype=np.float32)\n",
    "\n",
    "mat = cv2.getPerspectiveTransform(srcP, dstP)\n",
    "dst = cv2.warpPerspective(image, mat, (width,height))\n",
    "\n",
    "plt.imshow(cv2.cvtColor(dst,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QRコードの4角を使って平面射影変換する．\n",
    "image = cv2.imread('qr.png', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.show()\n",
    "    \n",
    "# QRコードの四隅の座標(srcP)⇒正方形の四隅の座標(dstP)への変換を行う平面射影行列を計算\n",
    "srcP = np.array([[608,1010],[991,1934],[1497,804],[1985,1564]], dtype=np.float32)\n",
    "dstP = np.array([[0,0],[0,500],[500,0],[500,500]], dtype=np.float32)\n",
    "    \n",
    "mat = cv2.getPerspectiveTransform(srcP, dstP)\n",
    "\n",
    "# 平面射影行列を用いて画像を変形\n",
    "dst = cv2.warpPerspective(image, mat, (500,500))\n",
    "plt.imshow(dst,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('title.png')\n",
    "plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e0b39ec2ec93d3f787b0b1de3964273a343f383fe8b2c7586e77803ff0c7afa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
