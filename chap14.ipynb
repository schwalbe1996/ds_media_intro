{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colabで開く](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/schwalbe1996/ds_media_intro/blob/main/chap14.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14章 「画像からの特徴抽出」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://github.com/schwalbe1996/ds_media_intro/raw/main/sample.png\n",
    "!wget -nc https://github.com/schwalbe1996/ds_media_intro/raw/main/roadscene.png\n",
    "!wget -nc https://github.com/schwalbe1996/ds_media_intro/raw/main/stopsign.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ノイズに対する影響を確認するため，ガウシアンノイズを加える\n",
    "image = cv2.imread('sample.png',cv2.IMREAD_GRAYSCALE)\n",
    "sigma = 5\n",
    "noise = np.random.normal(0, sigma, image.shape)\n",
    "image= image + noise\n",
    "    \n",
    "# 単にラプラシアンフィルタを適用したもの\n",
    "K_laplacian = np.array([[0,1,0],[1,-4,1],[0,1,0]])\n",
    "result_l = cv2.filter2D(image, ddepth=cv2.CV_64F, kernel=K_laplacian)\n",
    "\n",
    "# DoGフィルタを適用したもの\n",
    "sigma1, sigma2 = 1.3, 2.6\n",
    "ret1 = cv2.GaussianBlur(image, (3,3), sigma1)\n",
    "ret2 = cv2.GaussianBlur(image, (3,3), sigma2)\n",
    "dog = ret1 - ret2\n",
    "\n",
    "# Canny法\n",
    "edges = cv2.Canny(image.astype(np.uint8), 100, 200)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(np.abs(result_l), cmap='gray')\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(np.abs(dog),cmap='gray')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数edgeはCanny法でエッジ検出した結果\n",
    "lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=50, minLineLength=20, maxLineGap=3)\n",
    "print(f'{lines.shape[0]}本の線分が検出されました')\n",
    "    \n",
    "disp = image.copy()\n",
    "for l in lines: # 検出された各線分ごとに繰り返し\n",
    "    x0, y0, x1, y1 = l[0]\n",
    "    # 点(x0,y0)と点(x1,y1)とを結ぶ線分を画像に書き込む\n",
    "    cv2.line(disp, (x0,y0), (x1,y1), color=(255), thickness=2)    \n",
    "    \n",
    "plt.imshow(disp,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('sample.png', cv2.IMREAD_GRAYSCALE)\n",
    "SIFT = cv2.SIFT_create()\n",
    "keypoints, descriptors = SIFT.detectAndCompute(image, None)\n",
    "print(f'{len(keypoints)}個のキーポイントが検出')\n",
    "print(f'ひとつ目のキーポイントの位置と向き：{keypoints[0].pt},{keypoints[0].angle}')\n",
    "# print(descriptors[0]) # ひとつ目のキーポイントの特徴量（128次元ベクトル）\n",
    "disp = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imshow(disp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('roadscene.png', cv2.IMREAD_GRAYSCALE)\n",
    "sign = cv2.imread('stopsign.png' , cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "SIFT = cv2.SIFT_create()\n",
    "keypoints, descriptors = SIFT.detectAndCompute(image, None)\n",
    "s_keypoints, s_descriptors = SIFT.detectAndCompute(sign, None)\n",
    "disp = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "s_disp = cv2.drawKeypoints(sign, s_keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imshow(disp)\n",
    "plt.show()\n",
    "plt.imshow(s_disp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=50))\n",
    "matches = flann.knnMatch(s_descriptors, descriptors, k=2)   \n",
    "good = []\n",
    "for best,second in matches:\n",
    "    if best.distance < 0.7*second.distance:\n",
    "        good.append([best])\n",
    "print(f'{len(good)}個の対応点が見つかりました')\n",
    "for m in good:\n",
    "    s_pt = s_keypoints[m[0].queryIdx].pt\n",
    "    pt = keypoints[m[0].trainIdx].pt\n",
    "    print(f'標識:{s_pt}⇒画像:{pt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = cv2.drawMatchesKnn(sign,s_keypoints,image,keypoints,good,None)\n",
    "plt.imshow(disp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e0b39ec2ec93d3f787b0b1de3964273a343f383fe8b2c7586e77803ff0c7afa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
